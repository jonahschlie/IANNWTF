{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:10.287259Z",
     "start_time": "2023-12-09T16:49:07.239842Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:15.499614Z",
     "start_time": "2023-12-09T16:49:15.493327Z"
    }
   },
   "id": "daf0cbc6a135446a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:16.457988Z",
     "start_time": "2023-12-09T16:49:16.457072Z"
    }
   },
   "id": "e44a1f68bc8ba957"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def preprocessing(img,label):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = (img/128) -1\n",
    "    label = tf.one_hot(label, depth=10)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def load_and_prep_cifar(batch_size, shuffle_buffer_size):\n",
    "    (train_data, test_data), ds_info = tfds.load(name='cifar10',\n",
    "                                                split=['train','test'],\n",
    "                                                as_supervised=True,\n",
    "                                                with_info=True)\n",
    "    train_data = train_data.map(lambda img, label: preprocessing(img,label))\n",
    "    test_data = test_data.map(lambda img, label: preprocessing(img,label))\n",
    "    train_data = train_data.shuffle(shuffle_buffer_size).batch(batch_size).prefetch(20)\n",
    "    test_data = test_data.batch(batch_size).prefetch(20)\n",
    "    return train_data, test_data, ds_info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:17.282871Z",
     "start_time": "2023-12-09T16:49:17.281106Z"
    }
   },
   "id": "e6448e135fae74d7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class CNN_Model(tf.keras.Model):\n",
    "    def __init__(self, blocks: int, size_of_blocks: [int]):\n",
    "        if blocks != len(size_of_blocks):\n",
    "            raise ValueError(\"The number of blocks and the size of blocks must be the same\")\n",
    "        \n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "        \n",
    "        self.metrics_list = [\n",
    "                        tf.keras.metrics.Mean(name=\"loss\"),\n",
    "                        tf.keras.metrics.CategoricalAccuracy(name=\"acc\"),\n",
    "                       ]\n",
    "        \n",
    "        self.loss_f = tf.keras.losses.CategoricalCrossentropy()\n",
    "        \n",
    "        self.model_layers = []\n",
    "        \n",
    "        for block in range(blocks):\n",
    "            self.model_layers.append(tf.keras.layers.Conv2D(activation=\"relu\", filters=size_of_blocks[block], kernel_size=3, padding=\"same\"))\n",
    "            self.model_layers.append(tf.keras.layers.Conv2D(activation=\"relu\", filters=size_of_blocks[block], kernel_size=3, padding=\"same\"))\n",
    "            self.model_layers.append(tf.keras.layers.Conv2D(activation=\"relu\", filters=size_of_blocks[block], kernel_size=3, padding=\"same\"))\n",
    "            self.model_layers.append(tf.keras.layers.AvgPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "        self.global_pooling = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
    "       \n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        for layer in self.model_layers:\n",
    "            x = layer(x)\n",
    "        x = self.global_pooling(x)\n",
    "        output = self.output_layer(x)\n",
    "        return output\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics_list:\n",
    "            metric.reset_states()\n",
    "            \n",
    "            \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x, target = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self(x)\n",
    "            loss = self.loss_f(target, pred) + tf.reduce_sum(self.losses)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(grads_and_vars=zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        self.metrics[0].update_state(loss)\n",
    "        \n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(target, pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        x, target = data\n",
    "        pred = self(x)\n",
    "        loss = self.loss_f(target, pred) + tf.reduce_sum(self.losses)\n",
    "        \n",
    "        self.metrics[0].update_state(loss)\n",
    "        \n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(target, pred)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:18.079166Z",
     "start_time": "2023-12-09T16:49:18.076937Z"
    }
   },
   "id": "3cfc2cd320686ce3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = CNN_Model(4, [5,10,32,64])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:19.227934Z",
     "start_time": "2023-12-09T16:49:19.169222Z"
    }
   },
   "id": "20ebf0c5cf917c7c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Define where to save the log\n",
    "config_name= \"Run-1\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "test_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
    "\n",
    "# log writer for training metrics\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "# log writer for validation metrics\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:20.248348Z",
     "start_time": "2023-12-09T16:49:20.238822Z"
    }
   },
   "id": "a2537e3a74162389"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def training_loop(model, train, test, epochs, train_summary_writer, test_summary_writer):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #Training\n",
    "        for data in tqdm.tqdm(train, position=0, leave=True):\n",
    "            metrics = model.train_step(data)\n",
    "            with train_summary_writer.as_default():\n",
    "                for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "        \n",
    "        # print the metrics\n",
    "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        \n",
    "        # reset all metrics (requires a reset_metrics method in the model)\n",
    "        model.reset_metrics()\n",
    "\n",
    "        # Validation:\n",
    "        for data in test:\n",
    "            metrics = model.test_step(data)\n",
    "\n",
    "            # logging the validation metrics to the log file which is used by tensorboard\n",
    "            with test_summary_writer.as_default():\n",
    "                for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "\n",
    "        print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "\n",
    "        # reset all metrics\n",
    "        model.reset_metrics()\n",
    "        print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:49:25.481592Z",
     "start_time": "2023-12-09T16:49:25.478306Z"
    }
   },
   "id": "f4ea825dc81e4b25"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:20<00:00, 37.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.3209162950515747', 'acc: 0.5230748057365417']\n",
      "['val_loss: 1.3063057661056519', 'val_acc: 0.5285999774932861']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:19<00:00, 40.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.2064121961593628', 'acc: 0.5674600005149841']\n",
      "['val_loss: 1.1777360439300537', 'val_acc: 0.5741000175476074']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:19<00:00, 39.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.1282669305801392', 'acc: 0.5958399772644043']\n",
      "['val_loss: 1.1595337390899658', 'val_acc: 0.5866000056266785']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:19<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.0572736263275146', 'acc: 0.6214600205421448']\n",
      "['val_loss: 1.1001906394958496', 'val_acc: 0.6093999743461609']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:19<00:00, 40.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.0036523342132568', 'acc: 0.6421200037002563']\n",
      "['val_loss: 1.0338387489318848', 'val_acc: 0.632099986076355']\n"
     ]
    }
   ],
   "source": [
    "train, test, info = load_and_prep_cifar(batch_size=BATCH_SIZE, shuffle_buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "training_loop(model, train, test, 5, train_summary_writer, test_summary_writer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:52:18.684458Z",
     "start_time": "2023-12-09T16:50:31.443853Z"
    }
   },
   "id": "6b7a358c740cc68"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T16:54:42.178517Z",
     "start_time": "2023-12-09T16:54:37.609184Z"
    }
   },
   "id": "99d84a8b60258e5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "def train(num_epochs, batchsize, shuffle_buffer_size,lr):\n",
    "    model = CNN_Model(4, [5,10,32,64])\n",
    "    train, test, info = load_and_prep_cifar(batch_size=batchsize, shuffle_buffer_size=shuffle_buffer_size)\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=50000, decay_rate=0.96, staircase=True)\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule)\n",
    "    loss_f = tf.keras.losses.CategoricalCrossentropy()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        for x, t in train:\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = model(x)\n",
    "                l = loss_f(t, pred)\n",
    "            gradients = tape.gradient(l, model.trainable_variables)\n",
    "            optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\n",
    "            losses.append(l.numpy())\n",
    "        print(np.mean(losses))\n",
    "'''\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T15:21:07.079816Z"
    }
   },
   "id": "4f3c3c1333f612da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train(15, BATCH_SIZE, SHUFFLE_BUFFER_SIZE,lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T15:21:07.088184Z",
     "start_time": "2023-12-09T15:21:07.087738Z"
    }
   },
   "id": "264a7a7935dc5976"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T15:21:07.088121Z"
    }
   },
   "id": "df7519d9f916aaa0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
